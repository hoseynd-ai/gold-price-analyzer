#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dollar Index (DXY) Data Collection Service

Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¯Ù„Ø§Ø± Ø¢Ù…Ø±ÛŒÚ©Ø§ (DXY) Ø§Ø² Alpha Vantage

Ú†Ø±Ø§ Ù…Ù‡Ù…Ù‡:
- Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø¹Ú©ÙˆØ³ Ù‚ÙˆÛŒ Ø¨Ø§ Ø·Ù„Ø§ (correlation: -0.7 to -0.9)
- ÙˆÙ‚ØªÛŒ Ø¯Ù„Ø§Ø± Ù‚ÙˆÛŒ Ù…ÛŒØ´Ù‡ØŒ Ø·Ù„Ø§ Ø¶Ø¹ÛŒÙ Ù…ÛŒØ´Ù‡
- ÛŒÚ©ÛŒ Ø§Ø² Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø¹ÙˆØ§Ù…Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø·Ù„Ø§

Author: Hoseyn Doulabi (@hoseynd-ai)
Created: 2025-10-25 17:40:00 UTC
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, Dict, List
from sqlalchemy import select, and_
from sqlalchemy.orm import Session

from app.infrastructure.database.base import get_db, AsyncSessionLocal
from app.infrastructure.database.models import DollarIndexPrice
from app.core.config import settings
from app.core.logging import get_logger

logger = get_logger(__name__)


class DollarIndexService:
    """
    Ø³Ø±ÙˆÛŒØ³ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Dollar Index
    
    Dollar Index (DXY):
    - Ø´Ø§Ø®Øµ Ø§Ø±Ø²Ø´ Ø¯Ù„Ø§Ø± Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ø³Ø¨Ø¯ Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ
    - Ø´Ø§Ù…Ù„: EUR, JPY, GBP, CAD, SEK, CHF
    - ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒÙ†: ÛŒÙˆØ±Ùˆ (57.6%)
    
    Features:
    - Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Alpha Vantage
    - Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± database
    - Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ø±ÙˆØ²Ø§Ù†Ù‡
    - Correlation Ø¨Ø§ Ù‚ÛŒÙ…Øª Ø·Ù„Ø§
    """
    
    BASE_URL = "https://www.alphavantage.co/query"
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize Dollar Index service
        
        Args:
            api_key: Alpha Vantage API key
        """
        self.api_key = api_key or settings.ALPHA_VANTAGE_API_KEY
        
        if not self.api_key or self.api_key == "demo":
            logger.warning("alpha_vantage_demo_key",
                          message="Using demo key - limited functionality")
        
        logger.info("dollar_index_service_initialized")
    
    async def fetch_daily_data(
        self,
        outputsize: str = 'full'
    ) -> Optional[pd.DataFrame]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Dollar Index
        
        Args:
            outputsize: 'compact' (100 days) or 'full' (20+ years)
            
        Returns:
            DataFrame Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ: date, open, high, low, close, volume
        """
        logger.info("fetching_dollar_index_data", outputsize=outputsize)
        
        params = {
            'function': 'FX_DAILY',
            'from_symbol': 'USD',
            'to_symbol': 'EUR',  # EUR = Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† component DXY
            'outputsize': outputsize,
            'apikey': self.api_key
        }
        
        try:
            response = requests.get(self.BASE_URL, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # Ú†Ú© Ú©Ø±Ø¯Ù† Ø®Ø·Ø§
            if 'Error Message' in data:
                logger.error("api_error", error=data['Error Message'])
                return None
            
            if 'Note' in data:
                logger.warning("api_rate_limit", message=data['Note'])
                return None
            
            # Parse time series
            time_series_key = 'Time Series FX (Daily)'
            if time_series_key not in data:
                logger.error("unexpected_response_format", keys=list(data.keys()))
                return None
            
            time_series = data[time_series_key]
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            df = pd.DataFrame.from_dict(time_series, orient='index')
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()
            
            # ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            df.columns = ['open', 'high', 'low', 'close']
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ float
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ DXY inverse (Ú†ÙˆÙ† Ù…Ø§ USD/EUR Ø¯Ø§Ø±ÛŒÙ…)
            # DXY Ø¨Ø§Ù„Ø§ = Ø¯Ù„Ø§Ø± Ù‚ÙˆÛŒ = EUR/USD Ù¾Ø§ÛŒÛŒÙ†
            for col in ['open', 'high', 'low', 'close']:
                df[col] = 1 / df[col]
            
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ Ù…Ù‚ÛŒØ§Ø³ DXY ÙˆØ§Ù‚Ø¹ÛŒ (~100)
            # DXY base = 100 Ø¯Ø± Ø³Ø§Ù„ 1973
            df = df * 100
            
            logger.info("dollar_index_data_fetched",
                       records=len(df),
                       date_range=f"{df.index.min()} to {df.index.max()}")
            
            return df
            
        except requests.exceptions.RequestException as e:
            logger.error("request_error", error=str(e))
            return None
        except Exception as e:
            logger.error("unexpected_error", error=str(e))
            return None
    
    async def save_to_database(self, df: pd.DataFrame) -> int:
        """
        Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± database
        
        Args:
            df: DataFrame Ø­Ø§ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ DXY
            
        Returns:
            ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
        """
        logger.info("saving_dollar_index_to_db", records=len(df))
        
        saved_count = 0
        updated_count = 0
        
        async with AsyncSessionLocal() as session:
            for date, row in df.iterrows():
                try:
                    # Ú†Ú© ÙˆØ¬ÙˆØ¯
                    result = await session.execute(
                        select(DollarIndexPrice).where(
                            DollarIndexPrice.date == date.date()
                        )
                    )
                    existing = result.scalar_one_or_none()
                    
                    if existing:
                        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
                        existing.open = float(row['open'])
                        existing.high = float(row['high'])
                        existing.low = float(row['low'])
                        existing.close = float(row['close'])
                        existing.updated_at = datetime.utcnow()
                        updated_count += 1
                    else:
                        # Ø³Ø§Ø®Øª Ø¬Ø¯ÛŒØ¯
                        dxy_price = DollarIndexPrice(
                            date=date.date(),
                            open=float(row['open']),
                            high=float(row['high']),
                            low=float(row['low']),
                            close=float(row['close'])
                        )
                        session.add(dxy_price)
                        saved_count += 1
                    
                except Exception as e:
                    logger.warning("save_record_error",
                                 date=str(date.date()),
                                 error=str(e))
                    continue
            
            await session.commit()
        
        logger.info("dollar_index_saved",
                   saved=saved_count,
                   updated=updated_count,
                   total=saved_count + updated_count)
        
        return saved_count + updated_count
    
    async def get_latest_data(
        self,
        days: int = 30
    ) -> Optional[pd.DataFrame]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² database
        
        Args:
            days: ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø§Ø®ÛŒØ±
            
        Returns:
            DataFrame Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        """
        async with AsyncSessionLocal() as session:
            cutoff_date = datetime.utcnow().date() - timedelta(days=days)
            
            result = await session.execute(
                select(DollarIndexPrice)
                .where(DollarIndexPrice.date >= cutoff_date)
                .order_by(DollarIndexPrice.date.desc())
            )
            
            records = result.scalars().all()
            
            if not records:
                return None
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            data = [{
                'date': r.date,
                'open': r.open,
                'high': r.high,
                'low': r.low,
                'close': r.close
            } for r in records]
            
            df = pd.DataFrame(data)
            df['date'] = pd.to_datetime(df['date'])
            df = df.set_index('date').sort_index()
            
            return df
    
    async def calculate_correlation_with_gold(self) -> Dict:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Ù‚ÛŒÙ…Øª Ø·Ù„Ø§
        
        Returns:
            Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ correlation coefficient Ùˆ p-value
        """
        from app.infrastructure.database.models import GoldPriceFact
        
        async with AsyncSessionLocal() as session:
            # Ø¯Ø±ÛŒØ§ÙØª DXY data
            result_dxy = await session.execute(
                select(DollarIndexPrice).order_by(DollarIndexPrice.date)
            )
            dxy_records = result_dxy.scalars().all()
            
            # Ø¯Ø±ÛŒØ§ÙØª Gold data - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² timestamp Ø¨Ø¬Ø§ÛŒ date
            result_gold = await session.execute(
                select(GoldPriceFact)
                .where(GoldPriceFact.timeframe == 'daily')  # ÙÙ‚Ø· daily
                .order_by(GoldPriceFact.timestamp)
            )
            gold_records = result_gold.scalars().all()
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            dxy_df = pd.DataFrame([{
                'date': r.date,
                'dxy_close': float(r.close)
            } for r in dxy_records])
            
            gold_df = pd.DataFrame([{
                'date': r.timestamp.date(),  # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ date
                'gold_close': float(r.close)
            } for r in gold_records])
            
            # Merge on date
            merged = pd.merge(dxy_df, gold_df, on='date', how='inner')
            
            if len(merged) < 30:
                logger.warning("insufficient_data_for_correlation",
                             records=len(merged))
                return {
                    'correlation': None,
                    'p_value': None,
                    'samples': len(merged),
                    'interpretation': 'Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª'
                }
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ correlation
            correlation = merged['dxy_close'].corr(merged['gold_close'])
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ p-value
            from scipy.stats import pearsonr
            corr, p_value = pearsonr(merged['dxy_close'], merged['gold_close'])
            
            logger.info("correlation_calculated",
                       correlation=correlation,
                       p_value=p_value,
                       samples=len(merged))
            
            return {
                'correlation': float(correlation),
                'p_value': float(p_value),
                'samples': len(merged),
                'interpretation': self._interpret_correlation(correlation)
            }
    
    def _interpret_correlation(self, corr: float) -> str:
        """ØªÙØ³ÛŒØ± Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ"""
        if corr is None:
            return "Ù†Ø§Ù…Ø´Ø®Øµ"
        
        abs_corr = abs(corr)
        
        if abs_corr > 0.8:
            strength = "Ø®ÛŒÙ„ÛŒ Ù‚ÙˆÛŒ"
        elif abs_corr > 0.6:
            strength = "Ù‚ÙˆÛŒ"
        elif abs_corr > 0.4:
            strength = "Ù…ØªÙˆØ³Ø·"
        elif abs_corr > 0.2:
            strength = "Ø¶Ø¹ÛŒÙ"
        else:
            strength = "Ø®ÛŒÙ„ÛŒ Ø¶Ø¹ÛŒÙ"
        
        direction = "Ù…Ø¹Ú©ÙˆØ³" if corr < 0 else "Ù…Ø³ØªÙ‚ÛŒÙ…"
        
        return f"{strength} Ùˆ {direction}"
    
    async def get_statistics(self) -> Dict:
        """Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ DXY"""
        async with AsyncSessionLocal() as session:
            result = await session.execute(select(DollarIndexPrice))
            records = result.scalars().all()
            
            if not records:
                return {'total': 0}
            
            df = pd.DataFrame([{
                'date': r.date,
                'close': float(r.close)
            } for r in records])
            
            return {
                'total_records': len(records),
                'date_range': {
                    'start': str(df['date'].min()),
                    'end': str(df['date'].max())
                },
                'dxy_stats': {
                    'current': float(df.iloc[-1]['close']),
                    'min': float(df['close'].min()),
                    'max': float(df['close'].max()),
                    'mean': float(df['close'].mean()),
                    'std': float(df['close'].std())
                }
            }


if __name__ == "__main__":
    import asyncio
    
    async def main():
        print("\n" + "="*70)
        print("ğŸ’µ Dollar Index (DXY) Data Collection")
        print("="*70)
        print(f"ğŸ“… UTC: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ‘¤ User: hoseynd-ai")
        print("="*70 + "\n")
        
        service = DollarIndexService()
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡
        print("ğŸ“¥ Fetching Dollar Index data from Alpha Vantage...")
        df = await service.fetch_daily_data(outputsize='full')
        
        if df is not None:
            print(f"âœ… Data fetched: {len(df)} records")
            print(f"ğŸ“… Date range: {df.index.min().date()} to {df.index.max().date()}")
            print(f"\nğŸ“Š Latest DXY values:")
            print(df.tail())
            
            # Ø°Ø®ÛŒØ±Ù‡
            print(f"\nğŸ’¾ Saving to database...")
            saved = await service.save_to_database(df)
            print(f"âœ… Saved/Updated: {saved} records")
            
            # Correlation
            print(f"\nğŸ”— Calculating correlation with Gold...")
            corr_stats = await service.calculate_correlation_with_gold()
            
            if corr_stats['correlation'] is not None:
                print(f"âœ… Correlation: {corr_stats['correlation']:.4f}")
                print(f"   P-value: {corr_stats['p_value']:.6f}")
                print(f"   Samples: {corr_stats['samples']}")
                print(f"   ØªÙØ³ÛŒØ±: {corr_stats['interpretation']}")
            
            # Ø¢Ù…Ø§Ø±
            print(f"\nğŸ“ˆ Statistics:")
            stats = await service.get_statistics()
            print(f"   Total records: {stats['total_records']}")
            print(f"   Current DXY: {stats['dxy_stats']['current']:.2f}")
            print(f"   Range: {stats['dxy_stats']['min']:.2f} - {stats['dxy_stats']['max']:.2f}")
            print(f"   Average: {stats['dxy_stats']['mean']:.2f}")
        else:
            print("âŒ Failed to fetch data")
        
        print("\n" + "="*70 + "\n")
    
    asyncio.run(main())
